{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a8b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем библиотеки\n",
    "import nltk # Обработка естественного языка\n",
    "import numpy as np # Математика\n",
    "from sklearn.model_selection import train_test_split # Разделение выборки на обучающую и тестовую\n",
    "from collections import Counter # Подсчёт вхождений\n",
    "from collections import defaultdict # Словарь со значениями по умолчанию\n",
    "from keras.utils.np_utils import to_categorical # Унитарное кодирование\n",
    "\n",
    "# Библиотеки для нейросети\n",
    "import keras\n",
    "from keras import layers as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d4400",
   "metadata": {},
   "source": [
    "#### Загрузка и обработка занных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a39b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Pavel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Pavel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Модули для nltk\n",
    "nltk.download('brown') # Корпус английского языка, классифицированный по стилям\n",
    "nltk.download('universal_tagset') # Универсальный набор тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7e2db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Берём тренировочный датасет из nltk\n",
    "data = nltk.corpus.brown.tagged_sents(tagset = 'universal') # Заранее размеченный набор слов из общей категории \n",
    "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ'] # Тэги\n",
    "\n",
    "# В ячейках матрицы лежат отдельны предложения, они состоят из отдельных слов с тегами\n",
    "data = np.array([[(word.lower(), tag) for word, tag in sentence] for sentence in data], dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e936adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение выборки на обучающую и тестовую\n",
    "train_data, test_data = train_test_split(data, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b4922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage = 0.92876\n"
     ]
    }
   ],
   "source": [
    "# Подсчёт частотности слов\n",
    "word_counts = Counter()\n",
    "for sentence in data:\n",
    "    words, tags = zip(*sentence)\n",
    "    word_counts.update(words)\n",
    "\n",
    "# Берём 10000 наиболее встречаемых слов и теги '#EOS#', '#UNK#'    \n",
    "all_words = ['#EOS#', '#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n",
    "\n",
    "# Доля используемых слов от общего количества слов в словаре\n",
    "print(\"Coverage = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df774c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Присваиваем поряковые номера словам и тегам\n",
    "word_to_id = defaultdict(lambda:1, { word: i for i, word in enumerate(all_words) })\n",
    "tag_to_id = { tag: i for i, tag in enumerate(all_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a87cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция преобразования слов и тегов в матрицу\n",
    "def to_matrix(lines, token_to_id, max_len = None, pad = 0, dtype = 'int32', time_major = False):\n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    matrix = np.empty([len(lines), max_len], dtype)\n",
    "    matrix.fill(pad)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
    "        matrix[i,:len(line_ix)] = line_ix\n",
    "\n",
    "    return matrix.T if time_major else matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8822694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ids:\n",
      "[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n",
      "     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n",
      "     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n",
      "   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n",
      "     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n",
      "    12   10    2  861 5240   12    8 8936  121    1    4]\n",
      " [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n",
      "     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "Tag ids:\n",
      "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
      "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
      "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
      "   6  3  2 13  7]\n",
      " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим несколько элементов матрицы\n",
    "batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
    "\n",
    "print(\"Word ids:\")\n",
    "print(to_matrix(batch_words, word_to_id))\n",
    "print(\"Tag ids:\")\n",
    "print(to_matrix(batch_tags, tag_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4fba96",
   "metadata": {},
   "source": [
    "#### Модель рекуррентной нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84bf23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нейросеть последовательной архитектуры\n",
    "model = keras.models.Sequential()\n",
    "# Входной слой\n",
    "model.add(L.InputLayer([None], dtype = 'int32'))\n",
    "# Слой сжатия, количество входов равно количеству всех слов, выходов 50\n",
    "model.add(L.Embedding(len(all_words), 50))\n",
    "# Слой полносвязной рекррентной нейросети\n",
    "model.add(L.SimpleRNN(64, return_sequences = True))\n",
    "\n",
    "# Выходной слой размерностью равной количеству всех слов выдаёт веростности для тегов\n",
    "stepwise_dense = L.Dense(len(all_tags), activation = 'softmax')\n",
    "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
    "model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1776ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n",
    "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n",
    "    \n",
    "    while True:\n",
    "        indices = np.random.permutation(np.arange(len(sentences)))\n",
    "        for start in range(0,len(indices)-1,batch_size):\n",
    "            batch_indices = indices[start:start+batch_size]\n",
    "            batch_words,batch_tags = [],[]\n",
    "            for sent in sentences[batch_indices]:\n",
    "                words,tags = zip(*sent)\n",
    "                batch_words.append(words)\n",
    "                batch_tags.append(tags)\n",
    "\n",
    "            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n",
    "            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n",
    "\n",
    "            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n",
    "            yield batch_words,batch_tags_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fb5e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_accuracy(model):\n",
    "    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
    "    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n",
    "\n",
    "    #predict tag probabilities of shape [batch,time,n_tags]\n",
    "    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n",
    "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
    "\n",
    "    #compute accurary excluding padding\n",
    "    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n",
    "    denominator = np.sum(test_words != 0)\n",
    "    return float(numerator)/denominator\n",
    "\n",
    "\n",
    "class EvaluateAccuracy(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        sys.stdout.flush()\n",
    "        print(\"\\nMeasuring validation accuracy...\")\n",
    "        acc = compute_test_accuracy(self.model)\n",
    "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
    "\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4743f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1343/1343 [==============================] - 9s 6ms/step - loss: 0.2279\n",
      "Epoch 2/5\n",
      "1343/1343 [==============================] - 9s 7ms/step - loss: 0.0575\n",
      "Epoch 3/5\n",
      "1343/1343 [==============================] - 9s 7ms/step - loss: 0.0508\n",
      "Epoch 4/5\n",
      "1343/1343 [==============================] - 9s 7ms/step - loss: 0.0463\n",
      "Epoch 5/5\n",
      "1343/1343 [==============================] - 10s 7ms/step - loss: 0.0425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19fad3a3940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Собираем модель\n",
    "model.compile('adam', 'categorical_crossentropy')\n",
    "\n",
    "# Обучаем модель\n",
    "model.fit(generate_batches(train_data), steps_per_epoch = (len(train_data) / BATCH_SIZE), epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11217cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 2s 5ms/step\n",
      "Final accuracy: 0.94627\n"
     ]
    }
   ],
   "source": [
    "# Проверяем достигнутую точность\n",
    "acc = compute_test_accuracy(model)\n",
    "print(\"Final accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc>0.94, \"Keras has gone o9=-0367854 a rampage again, please contact course staff.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d366719",
   "metadata": {},
   "source": [
    "#### Модель двунаправленной рекуррентной нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88109299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нейросеть последовательной архитектуры\n",
    "model1 = keras.models.Sequential()\n",
    "# Входной слой\n",
    "model1.add(L.InputLayer([None], dtype = 'int32'))\n",
    "# Слой сжатия, количество входов равно количеству всех слов, выходов 50\n",
    "model1.add(L.Embedding(len(all_words), 50))\n",
    "# Слой двунаправленной рекррентной нейросети\n",
    "model1.add(L.Bidirectional(L.SimpleRNN(64, return_sequences = True)))\n",
    "\n",
    "# Выходной слой размерностью равной количеству всех слов выдаёт веростности для тегов\n",
    "stepwise_dense = L.Dense(len(all_tags), activation = 'softmax')\n",
    "stepwise_dense = L.TimeDistributed(stepwise_dense)\n",
    "model1.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "838e7424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1343/1343 [==============================] - 15s 10ms/step - loss: 0.1978\n",
      "Epoch 2/5\n",
      "1343/1343 [==============================] - 14s 10ms/step - loss: 0.0429\n",
      "Epoch 3/5\n",
      "1343/1343 [==============================] - 14s 10ms/step - loss: 0.0351\n",
      "Epoch 4/5\n",
      "1343/1343 [==============================] - 13s 10ms/step - loss: 0.0301\n",
      "Epoch 5/5\n",
      "1343/1343 [==============================] - 14s 10ms/step - loss: 0.0255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19fce0fd040>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Собираем модель\n",
    "model1.compile('adam', 'categorical_crossentropy')\n",
    "\n",
    "# Обучаем модель\n",
    "model1.fit(generate_batches(train_data), steps_per_epoch = (len(train_data) / BATCH_SIZE), epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23292786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 4s 8ms/step\n",
      "\n",
      "Final accuracy: 0.96125\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model1)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bd9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
